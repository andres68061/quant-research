{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-compute ML Results for Quick View\n",
    "\n",
    "This notebook pre-computes ML predictions for all commodities and frequencies.\n",
    "\n",
    "Run this overnight to populate the cache for instant Quick View demos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add src to path (handle both notebook/ and repo root execution)\n",
    "repo_root = Path.cwd()\n",
    "if repo_root.name == 'notebooks':\n",
    "    repo_root = repo_root.parent\n",
    "\n",
    "sys.path.insert(0, str(repo_root / 'src'))\n",
    "sys.path.insert(0, str(repo_root / 'apps'))\n",
    "\n",
    "print(f\"Repo root: {repo_root}\")\n",
    "print(f\"Python path: {sys.path[:3]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "\n",
    "from data.commodities import load_commodities_data, COMMODITIES_CONFIG\n",
    "from data.ml_features import create_ml_features_with_transparency\n",
    "from models.commodity_direction import compare_models\n",
    "from utils.ml_cache import save_ml_results\n",
    "\n",
    "print(\"‚úÖ Imports successful\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Symbols to pre-compute\n",
    "SYMBOLS = [\"GLD\", \"SLV\", \"GDX\"]  # Add more as needed\n",
    "\n",
    "# Frequencies to test\n",
    "FREQUENCIES = [\"Daily\", \"Weekly\", \"Monthly\"]\n",
    "\n",
    "# Model configurations (optimized for fast training)\n",
    "CONFIGS = {\n",
    "    \"Daily\": {\n",
    "        \"train_size\": 252,  # 1 year\n",
    "        \"test_size\": 5,     # 1 week\n",
    "        \"seq_len\": 60,      # 3 months\n",
    "        \"max_splits\": 50,   # Limit for speed\n",
    "    },\n",
    "    \"Weekly\": {\n",
    "        \"train_size\": 52,   # 1 year\n",
    "        \"test_size\": 4,     # 1 month\n",
    "        \"seq_len\": 20,      # 5 months\n",
    "        \"max_splits\": 50,\n",
    "    },\n",
    "    \"Monthly\": {\n",
    "        \"train_size\": 36,   # 3 years\n",
    "        \"test_size\": 3,     # 3 months\n",
    "        \"seq_len\": 12,      # 1 year\n",
    "        \"max_splits\": 50,\n",
    "    },\n",
    "}\n",
    "\n",
    "print(f\"Will pre-compute: {len(SYMBOLS)} symbols √ó {len(FREQUENCIES)} frequencies = {len(SYMBOLS) * len(FREQUENCIES)} total\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all commodity data\n",
    "df = load_commodities_data()\n",
    "\n",
    "print(f\"Loaded data: {df.shape}\")\n",
    "print(f\"Date range: {df.index.min()} to {df.index.max()}\")\n",
    "print(f\"Columns: {df.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-compute Results\n",
    "\n",
    "This will take a while! Estimated:\n",
    "- Daily: ~30 sec per symbol\n",
    "- Weekly: ~20 sec per symbol  \n",
    "- Monthly: ~15 sec per symbol\n",
    "\n",
    "**Total: ~5-10 minutes for 3 symbols √ó 3 frequencies**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_log = []\n",
    "\n",
    "for symbol in SYMBOLS:\n",
    "    if symbol not in df.columns:\n",
    "        print(f\"‚ö†Ô∏è Skipping {symbol} (not in data)\")\n",
    "        continue\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Processing {symbol} ({COMMODITIES_CONFIG[symbol]['name']})\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    price_series = df[symbol].dropna()\n",
    "    \n",
    "    for freq in FREQUENCIES:\n",
    "        print(f\"\\nüìä {freq} frequency...\")\n",
    "        \n",
    "        try:\n",
    "            # Resample if needed\n",
    "            if freq == \"Weekly\":\n",
    "                price_resampled = price_series.resample('W-FRI').last().dropna()\n",
    "            elif freq == \"Monthly\":\n",
    "                price_resampled = price_series.resample('M').last().dropna()\n",
    "            else:\n",
    "                price_resampled = price_series\n",
    "            \n",
    "            print(f\"  Data points: {len(price_resampled)}\")\n",
    "            \n",
    "            # Create features\n",
    "            features_df, metadata = create_ml_features_with_transparency(price_resampled, symbol=symbol)\n",
    "            print(f\"  Features: {features_df.shape[1]}, Rows: {len(features_df)}\")\n",
    "            \n",
    "            # Get config for this frequency\n",
    "            config = CONFIGS[freq]\n",
    "            \n",
    "            # Check data sufficiency\n",
    "            min_required = config['train_size'] + config['seq_len'] + config['test_size']\n",
    "            if len(features_df) < min_required:\n",
    "                print(f\"  ‚ùå Insufficient data: {len(features_df)} < {min_required}\")\n",
    "                results_log.append({\n",
    "                    'symbol': symbol,\n",
    "                    'freq': freq,\n",
    "                    'status': 'INSUFFICIENT_DATA',\n",
    "                    'rows': len(features_df),\n",
    "                    'required': min_required,\n",
    "                })\n",
    "                continue\n",
    "            \n",
    "            # Run comparison\n",
    "            start_time = datetime.now()\n",
    "            \n",
    "            results = compare_models(\n",
    "                features_df,\n",
    "                initial_train_days=config['train_size'],\n",
    "                test_days=config['test_size'],\n",
    "                max_splits=config['max_splits'],\n",
    "                xgb_params={'n_estimators': 100, 'max_depth': 3, 'learning_rate': 0.1},\n",
    "                lstm_params={\n",
    "                    'sequence_length': config['seq_len'],\n",
    "                    'hidden_units': 50,\n",
    "                    'dropout_rate': 0.2,\n",
    "                    'epochs': 20,\n",
    "                },\n",
    "                verbose=False,\n",
    "            )\n",
    "            \n",
    "            elapsed = (datetime.now() - start_time).total_seconds()\n",
    "            \n",
    "            # Save to cache\n",
    "            cache_metadata = {\n",
    "                'symbol': symbol,\n",
    "                'freq': freq,\n",
    "                'date': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "                'config': config,\n",
    "                'elapsed_seconds': elapsed,\n",
    "            }\n",
    "            \n",
    "            save_ml_results(symbol, freq, \"compare\", results, cache_metadata)\n",
    "            \n",
    "            # Log results\n",
    "            xgb_acc = results['xgboost']['overall_metrics']['accuracy']\n",
    "            lstm_acc = results['lstm']['overall_metrics']['accuracy']\n",
    "            winner = results['winner']\n",
    "            \n",
    "            print(f\"  ‚úÖ Complete in {elapsed:.0f}s\")\n",
    "            print(f\"     XGBoost: {xgb_acc:.1%}, LSTM: {lstm_acc:.1%}, Winner: {winner.upper()}\")\n",
    "            \n",
    "            results_log.append({\n",
    "                'symbol': symbol,\n",
    "                'freq': freq,\n",
    "                'status': 'SUCCESS',\n",
    "                'xgb_accuracy': xgb_acc,\n",
    "                'lstm_accuracy': lstm_acc,\n",
    "                'winner': winner,\n",
    "                'elapsed_seconds': elapsed,\n",
    "            })\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"  ‚ùå Error: {e}\")\n",
    "            results_log.append({\n",
    "                'symbol': symbol,\n",
    "                'freq': freq,\n",
    "                'status': 'ERROR',\n",
    "                'error': str(e),\n",
    "            })\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"‚úÖ Pre-computation complete!\")\n",
    "print(f\"{'='*60}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_df = pd.DataFrame(results_log)\n",
    "summary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Success rate\n",
    "success_count = (summary_df['status'] == 'SUCCESS').sum()\n",
    "total_count = len(summary_df)\n",
    "\n",
    "print(f\"\\nüìä Summary:\")\n",
    "print(f\"  Total: {total_count}\")\n",
    "print(f\"  Success: {success_count} ({success_count/total_count*100:.0f}%)\")\n",
    "print(f\"  Errors: {(summary_df['status'] == 'ERROR').sum()}\")\n",
    "print(f\"  Insufficient data: {(summary_df['status'] == 'INSUFFICIENT_DATA').sum()}\")\n",
    "\n",
    "if success_count > 0:\n",
    "    avg_time = summary_df[summary_df['status'] == 'SUCCESS']['elapsed_seconds'].mean()\n",
    "    print(f\"\\n‚è±Ô∏è Average time: {avg_time:.0f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List cached files\n",
    "from utils.ml_cache import list_cached_results\n",
    "\n",
    "cached = list_cached_results()\n",
    "print(f\"\\nüíæ Cached results ({len(cached)} files):\")\n",
    "for symbol, freq, model_type, path in cached:\n",
    "    size_mb = path.stat().st_size / (1024 * 1024)\n",
    "    print(f\"  {symbol:5} | {freq:7} | {model_type:10} | {size_mb:.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Done!\n",
    "\n",
    "Results are now cached in `outputs/ml_results/`.\n",
    "\n",
    "Use **Quick View mode** in Streamlit for instant access!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (quant)",
   "language": "python",
   "name": "quant"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
